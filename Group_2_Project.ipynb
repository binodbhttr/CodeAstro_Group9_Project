{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Neural network libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading data from: ', '/g/g15/nedwards/challenge_setup/data_and_information/galstar.csv')\n"
     ]
    }
   ],
   "source": [
    "current_path=!pwd\n",
    "a=str(current_path[0])\n",
    "c=a.replace(\"group_2\",\"\")\n",
    "data_path=c+\"challenge_setup/data_and_information/galstar.csv\"\n",
    "print(\"Reading data from: \",data_path)\n",
    "galstar = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31798, 5410)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galstar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = galstar.iloc[:,1:]\n",
    "Y=galstar[\"y\"]\n",
    "vals=[]\n",
    "X = X.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "count1=1\n",
    "for i in Y:\n",
    "    if(i==0):\n",
    "        count=count+1\n",
    "    if(i==1):\n",
    "        count1=count1+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of stars : 18665 count of Galaxiys : 13134\n"
     ]
    }
   ],
   "source": [
    "#PIE chart of y counts\n",
    "print(\"count of stars : \"+str(count)+\" count of Galaxiys : \"+str(count1))\n",
    "#visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n"
     ]
    }
   ],
   "source": [
    "vals=[]\n",
    "for j in np.arange(31798):\n",
    "    vals_temp=[]\n",
    "    for i in np.arange(8):\n",
    "        vals_temp.append(np.reshape(X.iloc[j].values[int(5408/8)*i:int(5408/8)*(i+1)],(26,26)))\n",
    "    vals.append(vals_temp)\n",
    "    if(j%100==0):\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(vals)\n",
    "X=vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Data\n",
    "class Astroid(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.X1=X\n",
    "        self.Y1=Y\n",
    "    def __getitem__(self, idx):\n",
    "        idx=idx.item()\n",
    "        tempX=self.X1[idx]\n",
    "        tempX=torch.tensor(tempX)\n",
    "        tempX=tempX.double()\n",
    "        tempY=self.Y1[idx]\n",
    "        if(tempY==1):\n",
    "            tempY=torch.tensor([0,1])  \n",
    "        else:\n",
    "            tempY=torch.tensor([1,0])\n",
    "            #(.2,.8)-[0]\n",
    "            #(.2,.8)[0 1] [1 0]\n",
    "            #\n",
    "            #\n",
    "        tempY=tempY.double()\n",
    "        return(tempX,tempY)\n",
    "       #returns batch(x,y)\n",
    "    def __len__(self):\n",
    "        return (len(self.X1))\n",
    "        #Length\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Astroid(X,Y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31798, 8, 26, 26)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize=22259\n",
    "testSize=9539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize+testSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,val_dataset=torch.utils.data.random_split(Data,[int(trainSize),int(testSize)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22259"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Astroid_Classifer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple model which takes 32x32 inputs and produces\n",
    "    score values for each of 10 classes for each element.\n",
    "    Model adapted from:\n",
    "    https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Astroid_Classifer,self).__init__()\n",
    "        # Features\n",
    "        self.conv1=nn.Conv2d(8,16,3)\n",
    "        self.pool1=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(16,32,3)\n",
    "        self.conv3=nn.Conv2d(32,64,3)\n",
    "        self.fc1=nn.Linear(64,48)#288/130\n",
    "        self.fc2=nn.Linear(48,32)#130/80\n",
    "        self.fc3=nn.Linear(32,16)#80/30\n",
    "        self.fc4=nn.Linear(16,2)#30/2\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Batch\n",
    "        \"\"\"\n",
    "        Pass one batch of image data through the model.\n",
    "        Return batch of score values corresponding to each class.\n",
    "        Input size: (batch_size, 1, 32, 32)\n",
    "        Output size: (batch_size, 10)\n",
    "        \"\"\"\n",
    "        x=self.pool1(F.relu(self.conv1(x)))\n",
    "        x=self.pool1(F.relu(self.conv2(x)))\n",
    "        x=self.pool1(F.relu(self.conv3(x)))\n",
    "        x=torch.flatten(x,1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=(self.fc4(x))  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Astroid_Classifer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "loss_total=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()\n",
    "optimzer=optim.Adagrad(model.parameters(),lr=.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------TRAIN-------------\n",
      "[1, 2000] | loss: 0.162 | accuracy: 0.779\n",
      "[1, 4000] | loss: 0.127 | accuracy: 0.828\n",
      "[1, 6000] | loss: 0.107 | accuracy: 0.857\n",
      "[1, 8000] | loss: 0.093 | accuracy: 0.882\n",
      "[1,10000] | loss: 0.091 | accuracy: 0.885\n",
      "[1,12000] | loss: 0.082 | accuracy: 0.901\n",
      "[1,14000] | loss: 0.089 | accuracy: 0.891\n",
      "[1,16000] | loss: 0.078 | accuracy: 0.901\n",
      "[1,18000] | loss: 0.076 | accuracy: 0.903\n",
      "[1,20000] | loss: 0.066 | accuracy: 0.927\n",
      "[1,22000] | loss: 0.075 | accuracy: 0.906\n",
      "-------------TRAIN-------------\n",
      "[2, 2000] | loss: 0.067 | accuracy: 0.917\n",
      "[2, 4000] | loss: 0.063 | accuracy: 0.922\n",
      "[2, 6000] | loss: 0.069 | accuracy: 0.920\n",
      "[2, 8000] | loss: 0.066 | accuracy: 0.921\n",
      "[2,10000] | loss: 0.059 | accuracy: 0.926\n",
      "[2,12000] | loss: 0.064 | accuracy: 0.925\n",
      "[2,14000] | loss: 0.070 | accuracy: 0.915\n",
      "[2,16000] | loss: 0.061 | accuracy: 0.928\n",
      "[2,18000] | loss: 0.065 | accuracy: 0.929\n",
      "[2,20000] | loss: 0.061 | accuracy: 0.929\n",
      "[2,22000] | loss: 0.058 | accuracy: 0.929\n",
      "-------------TRAIN-------------\n",
      "[3, 2000] | loss: 0.055 | accuracy: 0.934\n",
      "[3, 4000] | loss: 0.060 | accuracy: 0.926\n",
      "[3, 6000] | loss: 0.060 | accuracy: 0.925\n",
      "[3, 8000] | loss: 0.051 | accuracy: 0.940\n",
      "[3,10000] | loss: 0.058 | accuracy: 0.930\n",
      "[3,12000] | loss: 0.054 | accuracy: 0.941\n",
      "[3,14000] | loss: 0.053 | accuracy: 0.940\n",
      "[3,16000] | loss: 0.053 | accuracy: 0.932\n",
      "[3,18000] | loss: 0.055 | accuracy: 0.934\n",
      "[3,20000] | loss: 0.056 | accuracy: 0.934\n",
      "[3,22000] | loss: 0.060 | accuracy: 0.926\n",
      "-------------TRAIN-------------\n",
      "[4, 2000] | loss: 0.050 | accuracy: 0.939\n",
      "[4, 4000] | loss: 0.053 | accuracy: 0.934\n",
      "[4, 6000] | loss: 0.051 | accuracy: 0.942\n",
      "[4, 8000] | loss: 0.055 | accuracy: 0.932\n",
      "[4,10000] | loss: 0.055 | accuracy: 0.936\n",
      "[4,12000] | loss: 0.049 | accuracy: 0.946\n",
      "[4,14000] | loss: 0.046 | accuracy: 0.946\n",
      "[4,16000] | loss: 0.049 | accuracy: 0.943\n",
      "[4,18000] | loss: 0.049 | accuracy: 0.941\n",
      "[4,20000] | loss: 0.054 | accuracy: 0.934\n",
      "[4,22000] | loss: 0.051 | accuracy: 0.936\n",
      "-------------TRAIN-------------\n",
      "[5, 2000] | loss: 0.045 | accuracy: 0.946\n",
      "[5, 4000] | loss: 0.047 | accuracy: 0.939\n",
      "[5, 6000] | loss: 0.051 | accuracy: 0.939\n",
      "[5, 8000] | loss: 0.044 | accuracy: 0.943\n",
      "[5,10000] | loss: 0.048 | accuracy: 0.942\n",
      "[5,12000] | loss: 0.051 | accuracy: 0.936\n",
      "[5,14000] | loss: 0.045 | accuracy: 0.948\n",
      "[5,16000] | loss: 0.053 | accuracy: 0.938\n",
      "[5,18000] | loss: 0.043 | accuracy: 0.951\n",
      "[5,20000] | loss: 0.048 | accuracy: 0.942\n",
      "[5,22000] | loss: 0.050 | accuracy: 0.939\n",
      "-------------TRAIN-------------\n",
      "[6, 2000] | loss: 0.043 | accuracy: 0.948\n",
      "[6, 4000] | loss: 0.045 | accuracy: 0.947\n",
      "[6, 6000] | loss: 0.042 | accuracy: 0.947\n",
      "[6, 8000] | loss: 0.047 | accuracy: 0.945\n",
      "[6,10000] | loss: 0.043 | accuracy: 0.947\n",
      "[6,12000] | loss: 0.042 | accuracy: 0.951\n",
      "[6,14000] | loss: 0.051 | accuracy: 0.935\n",
      "[6,16000] | loss: 0.053 | accuracy: 0.932\n",
      "[6,18000] | loss: 0.046 | accuracy: 0.939\n",
      "[6,20000] | loss: 0.044 | accuracy: 0.941\n",
      "[6,22000] | loss: 0.046 | accuracy: 0.944\n",
      "-------------TRAIN-------------\n",
      "[7, 2000] | loss: 0.046 | accuracy: 0.943\n",
      "[7, 4000] | loss: 0.045 | accuracy: 0.946\n",
      "[7, 6000] | loss: 0.038 | accuracy: 0.956\n",
      "[7, 8000] | loss: 0.046 | accuracy: 0.942\n",
      "[7,10000] | loss: 0.042 | accuracy: 0.948\n",
      "[7,12000] | loss: 0.045 | accuracy: 0.945\n",
      "[7,14000] | loss: 0.051 | accuracy: 0.936\n",
      "[7,16000] | loss: 0.046 | accuracy: 0.945\n",
      "[7,18000] | loss: 0.039 | accuracy: 0.951\n",
      "[7,20000] | loss: 0.042 | accuracy: 0.946\n",
      "[7,22000] | loss: 0.045 | accuracy: 0.946\n",
      "-------------TRAIN-------------\n",
      "[8, 2000] | loss: 0.041 | accuracy: 0.948\n",
      "[8, 4000] | loss: 0.043 | accuracy: 0.948\n",
      "[8, 6000] | loss: 0.039 | accuracy: 0.954\n",
      "[8, 8000] | loss: 0.040 | accuracy: 0.951\n",
      "[8,10000] | loss: 0.042 | accuracy: 0.948\n",
      "[8,12000] | loss: 0.044 | accuracy: 0.939\n",
      "[8,14000] | loss: 0.047 | accuracy: 0.942\n",
      "[8,16000] | loss: 0.042 | accuracy: 0.944\n",
      "[8,18000] | loss: 0.042 | accuracy: 0.950\n",
      "[8,20000] | loss: 0.047 | accuracy: 0.942\n",
      "[8,22000] | loss: 0.041 | accuracy: 0.949\n",
      "-------------TRAIN-------------\n",
      "[9, 2000] | loss: 0.042 | accuracy: 0.947\n",
      "[9, 4000] | loss: 0.043 | accuracy: 0.944\n",
      "[9, 6000] | loss: 0.034 | accuracy: 0.959\n",
      "[9, 8000] | loss: 0.042 | accuracy: 0.949\n",
      "[9,10000] | loss: 0.040 | accuracy: 0.951\n",
      "[9,12000] | loss: 0.040 | accuracy: 0.951\n",
      "[9,14000] | loss: 0.036 | accuracy: 0.953\n",
      "[9,16000] | loss: 0.043 | accuracy: 0.941\n",
      "[9,18000] | loss: 0.044 | accuracy: 0.945\n",
      "[9,20000] | loss: 0.046 | accuracy: 0.944\n",
      "[9,22000] | loss: 0.041 | accuracy: 0.949\n",
      "-------------TRAIN-------------\n",
      "[10, 2000] | loss: 0.037 | accuracy: 0.953\n",
      "[10, 4000] | loss: 0.044 | accuracy: 0.948\n",
      "[10, 6000] | loss: 0.045 | accuracy: 0.946\n",
      "[10, 8000] | loss: 0.043 | accuracy: 0.945\n",
      "[10,10000] | loss: 0.042 | accuracy: 0.945\n",
      "[10,12000] | loss: 0.040 | accuracy: 0.948\n",
      "[10,14000] | loss: 0.044 | accuracy: 0.944\n",
      "[10,16000] | loss: 0.037 | accuracy: 0.954\n",
      "[10,18000] | loss: 0.039 | accuracy: 0.946\n",
      "[10,20000] | loss: 0.033 | accuracy: 0.963\n",
      "[10,22000] | loss: 0.039 | accuracy: 0.945\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss=float(0)\n",
    "    count=0.0\n",
    "    acc=0.0\n",
    "\n",
    "    print(\"-------------TRAIN-------------\")\n",
    "\n",
    "    for i, (input_x, label) in enumerate(train_dataloader):\n",
    "        optimzer.zero_grad()\n",
    "        input_x=input_x.float()#Conversion x64 tensor to float\n",
    "        outputs=model(input_x)#passes input tensor into model\n",
    "        count=count+1\n",
    "        label=label.float()\n",
    "        loss=criterion(outputs,label)# [1,0],[1]\n",
    "        \n",
    "        if(torch.max(outputs, 1)[1]==torch.max(label, 1)[1]):\n",
    "            acc=acc+1\n",
    "            \n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        running_loss+=loss.item()\n",
    "        if i % 2000==1999:\n",
    "            print('[%d,%5d] | loss: %.3f | accuracy: %.3f'%(epoch+1,i+1,running_loss/2000,acc/count))\n",
    "            accuracy.append(acc/count)\n",
    "            loss_total.append(running_loss/count)\n",
    "            count=0.0\n",
    "            acc=0.0\n",
    "            running_loss=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"Stars_and_Gal.pth.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight=model.state_dict()\n",
    "#torch.save(weight, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221,)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"loss.csv\", loss_total, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"Stars_and_Gal.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_params=torch.load(path)\n",
    "model.load_state_dict(loaded_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-4.1223e-03, -7.7201e-02, -1.1558e-01],\n",
       "                        [ 2.1949e-02,  4.0410e-02,  1.8808e-02],\n",
       "                        [-1.0402e-01,  6.4637e-02,  6.8546e-02]],\n",
       "              \n",
       "                       [[ 2.2622e-02,  2.2559e-02,  1.0506e-01],\n",
       "                        [-9.8768e-02,  8.4024e-02, -4.6891e-02],\n",
       "                        [-3.1909e-03, -7.2047e-02, -8.7380e-02]],\n",
       "              \n",
       "                       [[ 2.3805e-02, -2.6208e-02, -7.1921e-03],\n",
       "                        [ 7.8343e-02, -5.3850e-02,  7.5675e-02],\n",
       "                        [-2.6099e-02, -8.2156e-02,  5.0455e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0975e-01,  5.2992e-02, -4.1387e-03],\n",
       "                        [ 6.2066e-02,  1.8393e-02, -9.2548e-02],\n",
       "                        [ 1.3569e-02, -1.0103e-01, -1.0790e-01]],\n",
       "              \n",
       "                       [[ 3.1626e-02, -9.8024e-02,  7.0745e-02],\n",
       "                        [-2.8168e-02, -3.9079e-02,  6.3196e-03],\n",
       "                        [-9.0416e-02,  1.8372e-02, -3.9114e-02]],\n",
       "              \n",
       "                       [[ 4.3755e-03, -3.9824e-02,  2.4117e-02],\n",
       "                        [ 8.4873e-02,  5.1758e-02,  8.5137e-02],\n",
       "                        [ 2.3894e-02,  1.5970e-02,  3.7937e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1237e-02, -3.9915e-02, -2.8967e-02],\n",
       "                        [-3.0534e-02,  8.2104e-03,  3.4276e-02],\n",
       "                        [-1.1350e-01,  3.9352e-02, -1.9855e-02]],\n",
       "              \n",
       "                       [[ 1.3746e-02,  9.0673e-02, -1.0628e-01],\n",
       "                        [-4.8836e-02,  2.6929e-02, -1.7029e-02],\n",
       "                        [ 1.3877e-02,  3.1373e-02, -3.1218e-02]],\n",
       "              \n",
       "                       [[ 3.1893e-02,  7.5382e-02,  1.1456e-01],\n",
       "                        [ 4.9895e-02,  4.6032e-02,  3.0548e-02],\n",
       "                        [ 4.2419e-02, -3.1781e-02, -8.6365e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0990e-01, -4.1806e-03,  5.4308e-02],\n",
       "                        [-1.4977e-02,  5.0845e-02, -4.0183e-02],\n",
       "                        [ 7.7868e-03, -4.5493e-02,  2.2506e-02]],\n",
       "              \n",
       "                       [[ 3.3786e-02, -6.4020e-02,  1.7536e-02],\n",
       "                        [-1.1445e-01,  3.4541e-02,  3.7825e-02],\n",
       "                        [-4.1686e-02,  9.2525e-02,  4.1040e-02]],\n",
       "              \n",
       "                       [[-1.0564e-01, -1.0841e-01,  8.9597e-02],\n",
       "                        [ 1.2206e-02,  9.0535e-02,  6.9612e-02],\n",
       "                        [-3.2430e-02, -1.0714e-02,  3.6542e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6134e-02,  8.7294e-02,  3.8826e-02],\n",
       "                        [ 1.1724e-01,  9.1823e-02,  1.0811e-01],\n",
       "                        [-6.1585e-03, -7.4114e-02,  8.9314e-03]],\n",
       "              \n",
       "                       [[ 1.3061e-02,  4.4421e-02,  4.8697e-02],\n",
       "                        [ 9.4220e-02,  1.0807e-02,  3.8281e-02],\n",
       "                        [ 1.0340e-01, -7.7430e-02,  2.4618e-02]],\n",
       "              \n",
       "                       [[ 3.6775e-02,  2.0670e-02,  8.3878e-02],\n",
       "                        [ 6.7923e-02,  6.8912e-02,  3.1034e-02],\n",
       "                        [ 4.1133e-02,  3.5819e-02, -8.4886e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4535e-03,  8.3724e-02, -9.0336e-02],\n",
       "                        [ 9.9460e-02,  1.1888e-02, -6.1954e-02],\n",
       "                        [ 2.9560e-02,  7.4450e-02,  1.4140e-02]],\n",
       "              \n",
       "                       [[-6.7636e-02, -3.6954e-02,  6.5416e-03],\n",
       "                        [ 1.9797e-02, -3.1625e-02,  8.3604e-02],\n",
       "                        [-1.3492e-02,  7.8128e-02,  6.7091e-02]],\n",
       "              \n",
       "                       [[ 1.4378e-02,  5.1630e-02, -5.9413e-02],\n",
       "                        [-6.3241e-02,  7.3033e-02, -4.3419e-02],\n",
       "                        [-6.5534e-02,  2.0313e-02, -4.5118e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-7.1989e-02,  3.3328e-02,  8.9386e-02],\n",
       "                        [-5.7101e-02,  5.7067e-02, -9.4223e-02],\n",
       "                        [-3.7445e-02, -9.4022e-02, -1.0722e-01]],\n",
       "              \n",
       "                       [[ 3.4956e-02,  9.1029e-02,  1.0562e-01],\n",
       "                        [ 4.4887e-02, -1.0835e-02,  1.0530e-01],\n",
       "                        [ 1.2931e-02,  2.8212e-02, -7.4791e-02]],\n",
       "              \n",
       "                       [[-5.5947e-02,  4.7398e-02, -8.4260e-02],\n",
       "                        [-5.9778e-02,  5.9937e-02,  1.2978e-04],\n",
       "                        [-5.1758e-02, -7.6061e-02, -1.1156e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.0180e-02,  2.0082e-02, -8.3112e-02],\n",
       "                        [-9.5919e-02,  1.1531e-01,  9.3630e-02],\n",
       "                        [ 1.9450e-03,  1.0496e-01, -3.1515e-02]],\n",
       "              \n",
       "                       [[-8.6996e-03,  5.6651e-02, -6.1953e-02],\n",
       "                        [ 7.8642e-02,  1.1235e-01,  8.7958e-02],\n",
       "                        [ 6.0345e-02, -5.6007e-02, -8.8162e-02]],\n",
       "              \n",
       "                       [[-1.2233e-02, -8.6730e-02, -1.0288e-01],\n",
       "                        [ 1.1896e-02,  3.7312e-02,  7.6598e-02],\n",
       "                        [ 8.2691e-02, -5.9739e-02, -9.8946e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2422e-02,  1.0637e-01,  1.2223e-03],\n",
       "                        [-1.5367e-02,  3.2265e-02, -5.2056e-02],\n",
       "                        [ 8.1361e-02,  1.2696e-03,  1.0813e-01]],\n",
       "              \n",
       "                       [[-9.5879e-02, -1.1437e-01, -5.2152e-02],\n",
       "                        [-9.5714e-02, -5.7367e-02, -2.5102e-02],\n",
       "                        [-7.4112e-02,  6.9370e-02, -8.5124e-04]],\n",
       "              \n",
       "                       [[ 1.0676e-01, -8.2487e-02,  1.0034e-01],\n",
       "                        [ 7.8878e-03, -8.2917e-02,  2.8006e-02],\n",
       "                        [-1.1749e-04, -7.1945e-03, -2.9580e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0342e-01,  8.6552e-02, -1.0194e-01],\n",
       "                        [ 4.6308e-02,  7.0035e-02, -1.6072e-03],\n",
       "                        [ 1.0350e-01, -5.7904e-03,  1.5156e-02]],\n",
       "              \n",
       "                       [[-1.0773e-01,  9.0542e-02, -1.1751e-01],\n",
       "                        [ 1.3093e-02,  7.6661e-02, -1.1190e-01],\n",
       "                        [-1.0975e-01, -1.7648e-02,  3.7576e-02]],\n",
       "              \n",
       "                       [[-4.3462e-02, -1.4878e-03, -8.1305e-02],\n",
       "                        [ 4.1856e-02, -5.1269e-02,  1.6275e-02],\n",
       "                        [-9.5453e-02, -1.0932e-01,  7.5338e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9818e-03, -1.1434e-01, -5.7316e-02],\n",
       "                        [-8.5657e-02,  1.0193e-01, -4.3175e-02],\n",
       "                        [ 5.9439e-02,  8.1350e-02,  7.5497e-02]],\n",
       "              \n",
       "                       [[ 1.1725e-01, -2.9617e-02,  2.4462e-02],\n",
       "                        [-1.0759e-01, -9.7574e-02, -2.9682e-02],\n",
       "                        [ 4.0959e-02,  8.2363e-02, -6.6935e-02]],\n",
       "              \n",
       "                       [[ 7.7945e-03, -1.5817e-02,  1.0353e-01],\n",
       "                        [-4.8265e-02,  5.6478e-02, -6.2742e-02],\n",
       "                        [-9.8903e-02, -5.6902e-02, -8.7492e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.2250e-02,  4.8533e-02,  7.3428e-02],\n",
       "                        [ 1.1945e-02, -5.7734e-02, -5.3207e-02],\n",
       "                        [ 9.3732e-02, -4.5930e-02, -6.7481e-02]],\n",
       "              \n",
       "                       [[ 5.7270e-03,  1.0746e-01,  1.0935e-01],\n",
       "                        [-8.0990e-02,  4.8392e-02, -7.1303e-02],\n",
       "                        [-2.7019e-02,  2.7133e-02,  1.1173e-01]],\n",
       "              \n",
       "                       [[ 4.4203e-02,  8.8299e-02, -2.3122e-02],\n",
       "                        [-3.8690e-02, -1.9729e-02,  3.0867e-02],\n",
       "                        [ 1.0375e-01,  1.8002e-02,  9.9445e-02]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.1008, -0.0493, -0.0355, -0.0194,  0.0167,  0.1089, -0.0047, -0.0349,\n",
       "                       0.0916, -0.0738, -0.1117,  0.0512, -0.1145,  0.0466, -0.0856, -0.0825])),\n",
       "             ('conv2.weight', tensor([[[[ 0.0824,  0.0194,  0.0758],\n",
       "                        [-0.0521,  0.0492, -0.0806],\n",
       "                        [ 0.0380,  0.0128,  0.0177]],\n",
       "              \n",
       "                       [[ 0.0541,  0.0180, -0.0114],\n",
       "                        [ 0.0770, -0.0474,  0.0174],\n",
       "                        [-0.0146,  0.0744,  0.0129]],\n",
       "              \n",
       "                       [[ 0.0315,  0.0458, -0.0371],\n",
       "                        [-0.0075, -0.0403, -0.0236],\n",
       "                        [-0.0523,  0.0750,  0.0807]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0388,  0.0497,  0.0027],\n",
       "                        [-0.0019, -0.0704, -0.0158],\n",
       "                        [ 0.0594, -0.0256, -0.0154]],\n",
       "              \n",
       "                       [[-0.0714,  0.0591,  0.0109],\n",
       "                        [ 0.0776, -0.0264, -0.0761],\n",
       "                        [-0.0064, -0.0269,  0.0449]],\n",
       "              \n",
       "                       [[-0.0125,  0.0527,  0.0623],\n",
       "                        [ 0.0726, -0.0150,  0.0074],\n",
       "                        [ 0.0327, -0.0810, -0.0068]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0691, -0.0215, -0.0552],\n",
       "                        [-0.0817,  0.0172, -0.0252],\n",
       "                        [-0.0763,  0.0351,  0.0411]],\n",
       "              \n",
       "                       [[ 0.0613,  0.0708,  0.0463],\n",
       "                        [ 0.0596,  0.0509, -0.0666],\n",
       "                        [ 0.0479,  0.0556,  0.0620]],\n",
       "              \n",
       "                       [[ 0.0167, -0.0362, -0.0174],\n",
       "                        [ 0.0355,  0.0574, -0.0644],\n",
       "                        [ 0.0825,  0.0049, -0.0510]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0142,  0.0177, -0.0215],\n",
       "                        [ 0.0295, -0.0536, -0.0486],\n",
       "                        [ 0.0477, -0.0282, -0.0726]],\n",
       "              \n",
       "                       [[-0.0528, -0.0732, -0.0601],\n",
       "                        [-0.0451,  0.0165,  0.0222],\n",
       "                        [-0.0604,  0.0581,  0.0589]],\n",
       "              \n",
       "                       [[-0.0356, -0.0487,  0.0322],\n",
       "                        [-0.0639, -0.0402,  0.0166],\n",
       "                        [ 0.0749,  0.0398, -0.0601]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0541,  0.0062,  0.0721],\n",
       "                        [ 0.0807,  0.0424,  0.0582],\n",
       "                        [ 0.0505, -0.0528, -0.0124]],\n",
       "              \n",
       "                       [[-0.0623, -0.0362,  0.0488],\n",
       "                        [ 0.0211, -0.0251,  0.0491],\n",
       "                        [ 0.0638, -0.0494,  0.0667]],\n",
       "              \n",
       "                       [[ 0.0451,  0.0455,  0.0363],\n",
       "                        [-0.0589, -0.0421, -0.0438],\n",
       "                        [-0.0418,  0.0139, -0.0585]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0279, -0.0434, -0.0306],\n",
       "                        [ 0.0735,  0.0068, -0.0075],\n",
       "                        [ 0.0743, -0.0063,  0.0573]],\n",
       "              \n",
       "                       [[-0.0021,  0.0379, -0.0204],\n",
       "                        [-0.0402, -0.0404, -0.0053],\n",
       "                        [ 0.0061,  0.0200,  0.0667]],\n",
       "              \n",
       "                       [[ 0.0340,  0.0144, -0.0662],\n",
       "                        [ 0.0128, -0.0214, -0.0499],\n",
       "                        [-0.0780, -0.0524,  0.0457]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0287, -0.0718,  0.0744],\n",
       "                        [-0.0694, -0.0541, -0.0747],\n",
       "                        [ 0.0290,  0.0387,  0.0192]],\n",
       "              \n",
       "                       [[ 0.0592,  0.0481, -0.0207],\n",
       "                        [ 0.0375, -0.0185,  0.0390],\n",
       "                        [ 0.0610, -0.0199,  0.0698]],\n",
       "              \n",
       "                       [[ 0.0725,  0.0225, -0.0239],\n",
       "                        [-0.0350,  0.0567, -0.0794],\n",
       "                        [ 0.0173, -0.0518, -0.0065]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0506,  0.0694, -0.0212],\n",
       "                        [-0.0815,  0.0088, -0.0364],\n",
       "                        [-0.0712, -0.0252, -0.0533]],\n",
       "              \n",
       "                       [[-0.0451, -0.0706, -0.0250],\n",
       "                        [-0.0169, -0.0717, -0.0179],\n",
       "                        [ 0.0796, -0.0168, -0.0759]],\n",
       "              \n",
       "                       [[-0.0326, -0.0482, -0.0612],\n",
       "                        [-0.0238,  0.0240,  0.0598],\n",
       "                        [-0.0537,  0.0410,  0.0279]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0166, -0.0596, -0.0652],\n",
       "                        [ 0.0289, -0.0787,  0.0116],\n",
       "                        [-0.0641,  0.0285,  0.0151]],\n",
       "              \n",
       "                       [[ 0.0700, -0.0516, -0.0650],\n",
       "                        [ 0.0516,  0.0293, -0.0771],\n",
       "                        [-0.0641, -0.0698, -0.0748]],\n",
       "              \n",
       "                       [[ 0.0666,  0.0211, -0.0256],\n",
       "                        [ 0.0827,  0.0172,  0.0763],\n",
       "                        [-0.0201, -0.0423,  0.0545]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0270, -0.0727,  0.0425],\n",
       "                        [ 0.0559, -0.0550,  0.0366],\n",
       "                        [-0.0158, -0.0612,  0.0572]],\n",
       "              \n",
       "                       [[ 0.0078, -0.0728,  0.0272],\n",
       "                        [ 0.0128,  0.0086, -0.0637],\n",
       "                        [-0.0351, -0.0427, -0.0004]],\n",
       "              \n",
       "                       [[-0.0629,  0.0819,  0.0036],\n",
       "                        [ 0.0399, -0.0613, -0.0657],\n",
       "                        [-0.0252,  0.0618, -0.0637]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0801, -0.0072, -0.0302],\n",
       "                        [-0.0308,  0.0402, -0.0187],\n",
       "                        [-0.0220,  0.0243,  0.0783]],\n",
       "              \n",
       "                       [[-0.0222, -0.0104,  0.0722],\n",
       "                        [-0.0594,  0.0175, -0.0472],\n",
       "                        [ 0.0691,  0.0714,  0.0411]],\n",
       "              \n",
       "                       [[-0.0643,  0.0295, -0.0369],\n",
       "                        [-0.0283,  0.0233,  0.0117],\n",
       "                        [-0.0312,  0.0139, -0.0676]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0363, -0.0400, -0.0525],\n",
       "                        [ 0.0033, -0.0423, -0.0686],\n",
       "                        [ 0.0582, -0.0119, -0.0125]],\n",
       "              \n",
       "                       [[ 0.0656, -0.0496, -0.0762],\n",
       "                        [ 0.0808, -0.0339, -0.0730],\n",
       "                        [ 0.0280, -0.0707,  0.0577]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0023, -0.0532],\n",
       "                        [-0.0617,  0.0521, -0.0742],\n",
       "                        [-0.0770, -0.0726, -0.0445]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0277, -0.0043,  0.0582,  0.0442,  0.0711,  0.0160,  0.0380, -0.0272,\n",
       "                      -0.0605,  0.0114, -0.0185,  0.0523, -0.0365,  0.0519,  0.0193,  0.0435,\n",
       "                      -0.0713, -0.0270,  0.0781, -0.0432, -0.0805, -0.0054,  0.0762, -0.0406,\n",
       "                       0.0187, -0.0273, -0.0446, -0.0115,  0.0254,  0.0270, -0.0078, -0.0062])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[ 5.2613e-02,  1.3126e-04,  3.5748e-02],\n",
       "                        [ 2.4220e-02,  2.9127e-02,  8.6788e-02],\n",
       "                        [ 1.6123e-03, -7.0261e-03, -2.0204e-02]],\n",
       "              \n",
       "                       [[ 4.2423e-02, -5.5402e-02, -8.2895e-03],\n",
       "                        [-4.3332e-02,  3.5664e-02,  3.8113e-02],\n",
       "                        [-4.3181e-02, -4.4130e-02, -1.7167e-02]],\n",
       "              \n",
       "                       [[ 3.7670e-02,  5.6489e-02,  3.2595e-02],\n",
       "                        [ 1.1039e-02, -1.4142e-02, -9.5935e-02],\n",
       "                        [ 7.2253e-03, -3.0353e-02, -1.0958e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.4589e-02,  7.5537e-02,  2.9248e-02],\n",
       "                        [ 6.7535e-02, -1.3338e-02,  3.1672e-02],\n",
       "                        [-6.9387e-03, -1.0892e-02, -7.7460e-03]],\n",
       "              \n",
       "                       [[ 1.8538e-02,  2.4116e-03,  9.3154e-02],\n",
       "                        [ 1.1943e-02,  6.9443e-02,  1.4585e-02],\n",
       "                        [ 6.3094e-02,  7.2626e-03,  5.9177e-03]],\n",
       "              \n",
       "                       [[ 8.3388e-02,  7.6614e-02, -1.8909e-02],\n",
       "                        [ 2.6820e-03,  4.9421e-02,  8.0907e-02],\n",
       "                        [ 5.1268e-03,  6.9869e-02,  8.2599e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6507e-02,  5.5284e-02, -2.1530e-02],\n",
       "                        [-1.2083e-02,  3.4429e-02,  3.5170e-02],\n",
       "                        [ 2.2063e-02,  6.2796e-02, -4.6294e-02]],\n",
       "              \n",
       "                       [[-4.9506e-02, -5.7315e-02, -5.6847e-02],\n",
       "                        [-1.0047e-02,  1.2313e-02, -5.6202e-02],\n",
       "                        [-2.5523e-02, -5.6711e-02, -4.0331e-03]],\n",
       "              \n",
       "                       [[ 4.6828e-02,  2.2970e-02,  3.4043e-02],\n",
       "                        [ 9.4458e-02,  1.6467e-01,  1.6872e-01],\n",
       "                        [ 5.6155e-03,  2.0100e-01,  7.5090e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2548e-02, -4.2046e-02, -4.6413e-02],\n",
       "                        [-2.1653e-02, -6.7175e-02, -4.1252e-02],\n",
       "                        [-5.6655e-02,  5.7247e-02, -4.8740e-02]],\n",
       "              \n",
       "                       [[ 2.2048e-02, -7.9352e-03, -4.8376e-02],\n",
       "                        [ 3.9479e-02, -4.0037e-02, -5.5514e-02],\n",
       "                        [ 3.8499e-03, -2.7928e-02, -3.7958e-02]],\n",
       "              \n",
       "                       [[ 5.2603e-02,  4.6128e-02,  5.1409e-03],\n",
       "                        [-3.4516e-02, -1.0466e-02,  3.8880e-02],\n",
       "                        [-1.9379e-02, -8.2068e-03,  6.3098e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3209e-03,  4.5545e-02,  3.8353e-02],\n",
       "                        [-4.3631e-02,  1.5966e-02, -3.4134e-02],\n",
       "                        [-6.0488e-02,  2.3277e-02,  3.4961e-02]],\n",
       "              \n",
       "                       [[ 7.6282e-03, -2.1269e-02,  5.2687e-03],\n",
       "                        [ 2.8155e-02,  1.0894e-02, -2.8601e-02],\n",
       "                        [-2.3941e-02, -2.6240e-02,  2.8528e-02]],\n",
       "              \n",
       "                       [[ 8.4309e-03,  4.1260e-02,  9.0358e-03],\n",
       "                        [ 4.5840e-02,  1.4786e-01,  2.0970e-01],\n",
       "                        [ 4.1605e-02,  1.1521e-01,  1.7328e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.6914e-03, -2.1747e-03,  2.2664e-03],\n",
       "                        [-1.1001e-02, -6.3737e-02, -3.8962e-03],\n",
       "                        [-2.4013e-02, -6.3888e-02, -2.3431e-02]],\n",
       "              \n",
       "                       [[ 3.8456e-02, -2.7001e-02, -5.8879e-02],\n",
       "                        [ 1.1393e-02, -4.3006e-02,  1.5373e-02],\n",
       "                        [-3.5367e-02,  3.1062e-02,  8.6655e-03]],\n",
       "              \n",
       "                       [[ 4.0687e-02,  2.5764e-02,  4.3202e-02],\n",
       "                        [ 2.2915e-02, -3.2042e-02, -1.2630e-02],\n",
       "                        [ 1.1695e-02,  1.7288e-02,  3.5931e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.4601e-02,  3.7562e-03,  2.3756e-02],\n",
       "                        [-2.7450e-03,  5.2042e-02,  3.8074e-02],\n",
       "                        [-3.7648e-02, -5.6203e-02,  1.2654e-02]],\n",
       "              \n",
       "                       [[-4.9821e-04, -3.8096e-02,  1.0430e-02],\n",
       "                        [ 3.2836e-02,  3.5948e-02,  7.0065e-02],\n",
       "                        [ 4.2274e-03, -4.3715e-02,  5.4853e-02]],\n",
       "              \n",
       "                       [[ 6.4847e-02,  5.2787e-02,  2.0747e-02],\n",
       "                        [ 1.1918e-01, -1.9483e-03,  4.8729e-02],\n",
       "                        [ 9.4752e-02,  5.3147e-04,  5.6580e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7342e-02,  3.1103e-03, -5.8986e-02],\n",
       "                        [-3.0620e-02, -3.9558e-02, -3.7439e-02],\n",
       "                        [-5.0093e-02, -3.9453e-02, -5.5340e-02]],\n",
       "              \n",
       "                       [[-4.6639e-02,  5.4874e-02, -2.6121e-02],\n",
       "                        [-1.3659e-02, -8.6543e-03, -5.4259e-02],\n",
       "                        [-8.4129e-03, -3.0830e-02,  4.9158e-02]],\n",
       "              \n",
       "                       [[-5.5957e-02,  8.2692e-03,  4.4970e-02],\n",
       "                        [ 4.8177e-02, -1.7601e-02, -1.8074e-03],\n",
       "                        [-6.5363e-03, -3.6566e-02,  4.1769e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6686e-02,  4.8955e-02,  4.7759e-02],\n",
       "                        [ 7.3232e-02,  2.3884e-04,  7.6612e-02],\n",
       "                        [ 2.1928e-02,  5.1756e-03,  4.9310e-02]],\n",
       "              \n",
       "                       [[ 5.8830e-02, -1.8554e-02, -2.3573e-02],\n",
       "                        [ 7.8190e-04,  6.3966e-04, -5.5988e-02],\n",
       "                        [-3.8003e-02, -1.0922e-02,  3.3096e-02]],\n",
       "              \n",
       "                       [[-4.9789e-02, -2.3429e-02, -4.7466e-02],\n",
       "                        [ 6.7111e-02,  5.3847e-02,  9.4233e-02],\n",
       "                        [-5.4645e-02,  2.7386e-02,  3.8165e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.3478e-02,  3.6588e-02, -9.0751e-03],\n",
       "                        [ 7.8464e-02,  5.3855e-02,  8.8701e-02],\n",
       "                        [ 7.2401e-02,  5.8559e-02, -1.0646e-02]],\n",
       "              \n",
       "                       [[ 5.5570e-02,  1.1120e-02, -2.0732e-02],\n",
       "                        [ 3.5660e-02,  3.2905e-03,  4.9233e-02],\n",
       "                        [-1.8987e-02,  4.5534e-02,  3.1853e-02]],\n",
       "              \n",
       "                       [[ 7.3802e-02,  4.9140e-02, -5.8899e-03],\n",
       "                        [-3.8128e-03,  7.8517e-02,  3.8313e-02],\n",
       "                        [-2.3833e-02,  1.3885e-02,  6.0266e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0173e-02, -4.2833e-02,  5.6260e-03],\n",
       "                        [ 8.8542e-03,  5.5059e-02, -5.2817e-02],\n",
       "                        [-1.0912e-02, -3.7761e-02, -9.8030e-03]],\n",
       "              \n",
       "                       [[-2.3557e-04,  1.1772e-02,  3.6396e-02],\n",
       "                        [-1.7267e-03,  4.4662e-02, -3.5296e-02],\n",
       "                        [-2.4272e-02,  1.2660e-02, -5.0418e-02]],\n",
       "              \n",
       "                       [[ 3.4851e-02, -4.8256e-02, -2.8075e-02],\n",
       "                        [ 3.1774e-02, -8.1599e-03, -4.6849e-03],\n",
       "                        [-1.9620e-02, -7.7048e-03,  5.1393e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0072e-02, -5.3751e-02, -5.0358e-02],\n",
       "                        [-5.1419e-02,  2.0603e-02,  1.4993e-03],\n",
       "                        [-6.3154e-03, -1.6121e-02, -5.2963e-02]],\n",
       "              \n",
       "                       [[ 1.7281e-02, -4.8967e-03, -1.1154e-02],\n",
       "                        [ 1.6245e-02, -5.8037e-02, -2.8294e-03],\n",
       "                        [-1.2652e-02,  5.5354e-02,  2.7057e-02]],\n",
       "              \n",
       "                       [[-5.2778e-03, -9.4538e-03,  5.6138e-02],\n",
       "                        [-4.3890e-02,  4.5448e-02, -4.8142e-02],\n",
       "                        [ 3.8464e-03,  3.3291e-02, -2.1864e-02]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([ 9.4005e-02,  1.6795e-01, -2.1428e-02, -1.1174e-01,  1.5062e-01,\n",
       "                       6.5411e-02, -1.7597e-01, -1.3062e-01,  1.1809e-01, -1.5317e-01,\n",
       "                      -2.1895e-02,  8.0468e-02,  1.4232e-01, -1.2796e-01, -8.4781e-02,\n",
       "                      -1.1357e-02, -7.7270e-02,  6.6908e-02,  1.0607e-01, -1.2764e-02,\n",
       "                      -1.6215e-01, -3.6019e-02, -3.1984e-02, -1.5894e-01, -1.1679e-02,\n",
       "                       3.1450e-02, -1.5881e-01, -2.7248e-02,  3.8173e-02, -1.3562e-01,\n",
       "                       1.1749e-01,  1.4122e-04,  1.4221e-01,  1.6231e-01,  1.3047e-01,\n",
       "                       9.3622e-02,  1.3264e-01,  1.6635e-01, -6.9272e-02,  7.8075e-02,\n",
       "                       3.6795e-02, -1.6297e-01, -1.4497e-01,  3.3898e-02, -5.6844e-02,\n",
       "                       4.7895e-02,  9.8607e-02, -1.1317e-01, -1.2779e-02, -1.7536e-01,\n",
       "                      -1.5592e-01,  2.2068e-02,  2.9205e-03,  1.6577e-01, -1.3833e-01,\n",
       "                       5.9483e-02, -1.2804e-01,  4.5742e-02,  7.9064e-02, -8.2050e-02,\n",
       "                       7.5065e-02, -9.9903e-02, -3.4149e-03,  4.3435e-02])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0682,  0.0687,  0.1944,  ...,  0.0444, -0.0437,  0.0567],\n",
       "                      [ 0.0527,  0.1168, -0.0207,  ...,  0.0215,  0.0772,  0.0817],\n",
       "                      [ 0.0137, -0.0764, -0.0940,  ..., -0.0348,  0.0597, -0.1126],\n",
       "                      ...,\n",
       "                      [ 0.0776,  0.1313,  0.0704,  ...,  0.0673,  0.1162,  0.0829],\n",
       "                      [-0.0347, -0.1137, -0.0702,  ...,  0.1128, -0.0302,  0.0150],\n",
       "                      [ 0.0226,  0.1425, -0.0245,  ..., -0.0800, -0.0733,  0.0829]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0566,  0.1105,  0.1223, -0.0043,  0.1233, -0.0261,  0.1407,  0.0286,\n",
       "                      -0.0156, -0.0457, -0.0093,  0.0284, -0.0788,  0.1107,  0.0265, -0.0144,\n",
       "                       0.0308,  0.1075,  0.0847, -0.0082, -0.1213,  0.0739, -0.0570, -0.1163,\n",
       "                       0.1254, -0.1032, -0.0935, -0.0901, -0.0117, -0.1244, -0.0624, -0.0365,\n",
       "                      -0.0158, -0.0696,  0.0286, -0.0697,  0.0881, -0.0592, -0.0214,  0.0899,\n",
       "                      -0.0890,  0.0597, -0.0720, -0.0789, -0.0645, -0.0516, -0.1121,  0.0446])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0063, -0.0137,  0.0874,  ...,  0.0784,  0.1338,  0.0750],\n",
       "                      [-0.0144,  0.1283, -0.1059,  ...,  0.1481, -0.1250,  0.0883],\n",
       "                      [ 0.0963, -0.0426, -0.0489,  ..., -0.1140, -0.1029, -0.0842],\n",
       "                      ...,\n",
       "                      [-0.1436, -0.0494, -0.0359,  ..., -0.0792,  0.1400,  0.0479],\n",
       "                      [-0.0282,  0.1385,  0.1359,  ...,  0.0824,  0.0271, -0.1124],\n",
       "                      [-0.0462,  0.0822,  0.0386,  ..., -0.0654,  0.0831,  0.1071]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0007,  0.0552, -0.0417, -0.0863, -0.0233,  0.0290, -0.0651, -0.0784,\n",
       "                      -0.0770, -0.0379,  0.0207, -0.0757, -0.1164,  0.1038, -0.0043,  0.0124,\n",
       "                       0.1283, -0.1333, -0.1383,  0.1474,  0.0607,  0.1071,  0.0907,  0.0412,\n",
       "                      -0.1292,  0.0768, -0.0589,  0.1685, -0.1469,  0.0155, -0.0100, -0.0162])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0904, -0.1212, -0.1379, -0.1342,  0.1672, -0.0926, -0.0633,  0.0474,\n",
       "                       -0.1162, -0.0267,  0.1888,  0.1597, -0.1699,  0.1517, -0.0902,  0.0658,\n",
       "                       -0.1220, -0.0879, -0.1309,  0.1409, -0.0607,  0.1779,  0.1578, -0.0045,\n",
       "                        0.1086, -0.1173, -0.0730,  0.0061,  0.0185,  0.0407, -0.0040, -0.1469],\n",
       "                      [-0.0433, -0.0195, -0.0870, -0.0112,  0.0731,  0.0358,  0.0816, -0.0799,\n",
       "                        0.0491,  0.1176, -0.1081, -0.0652,  0.1149,  0.0233, -0.0371, -0.1672,\n",
       "                       -0.1724,  0.1636,  0.1555,  0.0010,  0.0144,  0.0866,  0.0688, -0.0015,\n",
       "                        0.0647, -0.1252, -0.1259,  0.1366, -0.1491, -0.0695, -0.1632, -0.1631],\n",
       "                      [ 0.0566,  0.0814, -0.1008,  0.0111,  0.1090,  0.0989,  0.0341,  0.1442,\n",
       "                       -0.1074, -0.1333, -0.0260, -0.0437,  0.1382,  0.0855, -0.1266, -0.0073,\n",
       "                        0.1112,  0.0649, -0.0745,  0.1269,  0.1998, -0.1258,  0.0555,  0.1472,\n",
       "                        0.0611, -0.1386, -0.1147, -0.0100,  0.1578, -0.1152,  0.1620,  0.0062],\n",
       "                      [-0.1417, -0.1335,  0.1218, -0.0589, -0.0442, -0.0164,  0.0743, -0.1709,\n",
       "                        0.0207, -0.1747,  0.1416,  0.1453, -0.0792,  0.1429,  0.1855, -0.0172,\n",
       "                        0.1858, -0.1252,  0.1011, -0.0443, -0.0814, -0.0816,  0.1045,  0.1258,\n",
       "                       -0.1374, -0.1340, -0.1440,  0.0912,  0.0858, -0.0978, -0.1217,  0.0480],\n",
       "                      [-0.0685, -0.1534, -0.0810,  0.1381, -0.0173, -0.1765, -0.1452, -0.0717,\n",
       "                        0.0074,  0.0711,  0.1303, -0.0458,  0.0106, -0.0591, -0.1284, -0.0282,\n",
       "                       -0.0479,  0.0892,  0.1296,  0.1318, -0.1448,  0.0534, -0.0024,  0.0049,\n",
       "                        0.0788,  0.1676, -0.0685,  0.0587, -0.0392,  0.1176, -0.1550, -0.0233],\n",
       "                      [-0.0955, -0.1810, -0.0583, -0.0166,  0.0849, -0.0645,  0.1061, -0.0599,\n",
       "                        0.0616, -0.1561,  0.0144,  0.1777, -0.0529,  0.0629, -0.0646, -0.0886,\n",
       "                       -0.0638,  0.1316,  0.1149,  0.0352,  0.0923,  0.0150,  0.1883,  0.0539,\n",
       "                       -0.0150, -0.0062,  0.1164,  0.0889,  0.0867,  0.1228, -0.1280,  0.1479],\n",
       "                      [-0.0644, -0.0807,  0.0788, -0.1731,  0.0280, -0.0989, -0.0492,  0.1004,\n",
       "                       -0.0960,  0.1704, -0.1983, -0.0717, -0.0950, -0.1846,  0.0965,  0.1029,\n",
       "                        0.0948,  0.1567,  0.2113,  0.1722, -0.0396, -0.0677, -0.0059, -0.0511,\n",
       "                        0.0274,  0.1393, -0.0858,  0.1101, -0.1445, -0.1491, -0.0690,  0.0840],\n",
       "                      [-0.0810,  0.1044,  0.0701, -0.0683, -0.1267, -0.0971, -0.0724, -0.1634,\n",
       "                       -0.0581,  0.0469, -0.1897,  0.0287, -0.1329, -0.0368,  0.1395,  0.1206,\n",
       "                        0.0291, -0.0473, -0.1130,  0.0775,  0.0574, -0.1981,  0.0441,  0.0580,\n",
       "                       -0.0122,  0.1268, -0.0480, -0.0469, -0.1374,  0.0513, -0.1349, -0.1485],\n",
       "                      [-0.1388,  0.1865, -0.1110, -0.0734, -0.1243,  0.1151,  0.1686,  0.0332,\n",
       "                       -0.1775,  0.0329, -0.1952, -0.1676,  0.1176, -0.0817,  0.2396,  0.0567,\n",
       "                       -0.1264, -0.0712,  0.0414, -0.0745,  0.1114, -0.1585,  0.1363,  0.0882,\n",
       "                        0.1053,  0.1112, -0.1118,  0.0580,  0.0167, -0.0743,  0.1497,  0.0597],\n",
       "                      [ 0.1190, -0.0560,  0.1514,  0.0577, -0.0645, -0.0905, -0.1321,  0.1324,\n",
       "                       -0.0568, -0.1733,  0.1581,  0.1719,  0.0958,  0.1324, -0.2483,  0.1147,\n",
       "                        0.0834, -0.1158, -0.1309,  0.0562,  0.0536,  0.1314,  0.0530, -0.0243,\n",
       "                        0.0940, -0.2001,  0.0620,  0.1194, -0.1375,  0.0836, -0.1623, -0.0143],\n",
       "                      [-0.0577, -0.0300,  0.0329, -0.0843,  0.0160,  0.0650,  0.0963, -0.0052,\n",
       "                       -0.1112, -0.0376,  0.0406, -0.0032, -0.0264,  0.0569, -0.0509, -0.1424,\n",
       "                        0.0489,  0.1767,  0.0834,  0.0244, -0.1179,  0.1467,  0.0335, -0.1424,\n",
       "                        0.1111,  0.0030, -0.1488, -0.0091, -0.1371,  0.0043, -0.0917,  0.0816],\n",
       "                      [ 0.1475, -0.0821, -0.1390, -0.0384,  0.1204, -0.0292, -0.1638, -0.0932,\n",
       "                       -0.0353,  0.0087, -0.0048, -0.0531, -0.1275,  0.1515, -0.1616,  0.1096,\n",
       "                       -0.1584, -0.0676, -0.0127,  0.0943, -0.1627,  0.0099, -0.1338,  0.1173,\n",
       "                       -0.0760,  0.0372,  0.1105,  0.0209, -0.1512, -0.0968,  0.0940, -0.0090],\n",
       "                      [-0.2156, -0.0223, -0.1415, -0.0812, -0.0979, -0.1468, -0.0741, -0.0961,\n",
       "                       -0.1017, -0.1234, -0.1219, -0.0490, -0.1567,  0.1546, -0.0727,  0.1697,\n",
       "                        0.0351, -0.0430,  0.2303,  0.1485, -0.0411,  0.1082, -0.0535, -0.0293,\n",
       "                        0.1868,  0.0232, -0.0479,  0.1687,  0.1794,  0.1150, -0.1803,  0.0417],\n",
       "                      [ 0.0806, -0.0135,  0.0092, -0.0928, -0.1796,  0.0680,  0.1453, -0.1643,\n",
       "                       -0.0266,  0.0122,  0.0406,  0.0288,  0.0787,  0.0899,  0.0572, -0.0725,\n",
       "                        0.1375, -0.0098,  0.1509,  0.1374,  0.0836, -0.1810,  0.0006,  0.0172,\n",
       "                       -0.0184, -0.0862,  0.0492, -0.0505,  0.0709, -0.1396, -0.0620, -0.0758],\n",
       "                      [ 0.1094,  0.1246, -0.1509, -0.0340, -0.0156, -0.0994, -0.1521,  0.0928,\n",
       "                       -0.0755, -0.1754,  0.1598,  0.1142, -0.1756,  0.1441, -0.0701, -0.1739,\n",
       "                       -0.1101, -0.1529, -0.0899,  0.0409, -0.1511, -0.0215, -0.1419,  0.0041,\n",
       "                       -0.0126, -0.0973,  0.1264,  0.1760,  0.1693, -0.1570, -0.0887,  0.0681],\n",
       "                      [-0.0804, -0.1028, -0.1390,  0.0676, -0.0246, -0.1060,  0.0976,  0.0292,\n",
       "                        0.0983, -0.0062,  0.0597,  0.1399,  0.0742,  0.2155, -0.2101, -0.0406,\n",
       "                       -0.0184, -0.0052, -0.1388,  0.0940, -0.0150, -0.0681, -0.0248,  0.1066,\n",
       "                       -0.0896, -0.0763,  0.0759, -0.0254,  0.1336,  0.0430,  0.1690,  0.1286]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0127,  0.0701,  0.1113, -0.1524, -0.0564,  0.0723,  0.0831,  0.0176,\n",
       "                       0.0802,  0.1175,  0.1615,  0.0802,  0.0835, -0.1052,  0.1445,  0.0624])),\n",
       "             ('fc4.weight',\n",
       "              tensor([[ 0.1897, -0.0183,  0.2575,  0.0962,  0.1657,  0.1999, -0.0883, -0.1096,\n",
       "                       -0.1246,  0.0680, -0.0925, -0.0884, -0.0923,  0.0649,  0.2995,  0.2412],\n",
       "                      [-0.1730, -0.2175,  0.2278,  0.1034, -0.0328,  0.1541,  0.3018,  0.0109,\n",
       "                        0.2386, -0.1686,  0.2585, -0.2239,  0.2105,  0.1530, -0.2098,  0.1573]])),\n",
       "             ('fc4.bias', tensor([-0.0506,  0.0371]))])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-117-47e32cc3cb2a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-117-47e32cc3cb2a>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    input_val, labels = data\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "        input_val, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(input_val)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test ima2ges: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucmenv",
   "language": "python",
   "name": "ucmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
